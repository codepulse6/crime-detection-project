import urllib.request
import urllib.parse
import csv
from datetime import datetime
import json
from html.parser import HTMLParser
import sys

# ====================== CONFIGURATION ======================
CONFIG = {
    "keywords": ["crime", "murder", "robbery", "shooting"],
    "max_posts": 5  # Very small limit for online compilers
}

# ====================== SIMPLE HTML PARSER ======================
class SimpleHTMLParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.links = []
    
    def handle_starttag(self, tag, attrs):
        if tag == "a":
            attrs = dict(attrs)
            if "href" in attrs:
                self.links.append(attrs["href"])

# ====================== NEWS SCRAPER (NO DEPENDENCIES) ======================
class NewsScraper:
    @staticmethod
    def fetch_google_news(query):
        try:
            url = f"https://news.google.com/search?q={urllib.parse.quote(query)}"
            req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
            
            with urllib.request.urlopen(req, timeout=10) as response:
                html = response.read().decode()
                parser = SimpleHTMLParser()
                parser.feed(html)
                
                # Filter for actual news links
                news_links = [link for link in parser.links 
                             if link.startswith("./articles/")]
                
                # Get first few results
                results = []
                base_url = "https://news.google.com"
                for link in news_links[:CONFIG["max_posts"]]:
                    full_url = base_url + link[1:]
                    title = link.split("=")[-1].replace("+", " ")
                    if any(kw.lower() in title.lower() for kw in CONFIG["keywords"]):
                        results.append({
                            "title": title,
                            "url": full_url,
                            "source": "Google News"
                        })
                return results
                
        except Exception as e:
            print(f"[Error] Could not fetch news: {e}")
            return []

# ====================== MAIN APP ======================
def main():
    print("=== Crime News Finder ===")
    print("(Using built-in libraries only)\n")
    
    try:
        # Simple year input (for demonstration)
        start_year = input("Enter start year (e.g. 2020): ")
        end_year = input("Enter end year (e.g. 2023): ")
        
        print(f"\nSearching for crime news...")
        
        # Fetch news
        news = NewsScraper.fetch_google_news("crime")
        
        # Display results
        print(f"\nFound {len(news)} relevant news items:")
        for idx, item in enumerate(news, 1):
            print(f"\n{idx}. {item['title']}")
            print(f"   Source: {item['source']}")
            print(f"   URL: {item['url']}")
            
        print("\nNote: Online compilers may block web requests.")
        
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
